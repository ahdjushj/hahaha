{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a62e1f6a-3413-4609-a54e-c85567f10ce0",
   "metadata": {},
   "source": [
    "# 项目"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81acb28a-f1ac-4b8b-8400-79e4fdadee9b",
   "metadata": {},
   "source": [
    "## 代码核心功能说明"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d40b566-7f15-4405-a51f-00be94abac75",
   "metadata": {},
   "source": [
    "### 1. 获取邮件内容并切词处理 (get_words 函数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7cfec74-e133-4545-83fb-9197b49b236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(filename):\n",
    "    words = []\n",
    "    with open(filename, 'r', encoding='utf-8') as fr:\n",
    "        for line in fr:\n",
    "            line = line.strip()\n",
    "            line = re.sub(r'[.【】0-9、——。，！~\\*]', '', line)  # 过滤无效字符\n",
    "            line = cut(line)  # jieba分词\n",
    "            line = filter(lambda word: len(word) > 1, line)  # 过滤长度为1的词\n",
    "            words.extend(line)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2d019b-5b27-4515-b850-7c147a4e374d",
   "metadata": {},
   "source": [
    "### 2.构建词汇表并提取频率较高的词(get_top_words 函数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c049b57-838a-4127-96d8-29a4c83855d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(top_num):\n",
    "    filename_list = ['邮件_files/{}.txt'.format(i) for i in range(151)]\n",
    "    for filename in filename_list:\n",
    "        all_words.append(get_words(filename))  # 遍历所有邮件生成词库\n",
    "    freq = Counter(chain(*all_words))  # 统计词频\n",
    "    return [i[0] for i in freq.most_common(top_num)]  # 返回前 top_num 个高频词"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4abe0-7da4-4c0a-8802-96f5000c8cdd",
   "metadata": {},
   "source": [
    "### 3. 构建邮件的词向量 (vector 生成部分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5083d495-876a-4027-8109-da2d275989c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m vector \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m words \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_words\u001b[49m:\n\u001b[0;32m      3\u001b[0m     word_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m word: words\u001b[38;5;241m.\u001b[39mcount(word), top_words))  \u001b[38;5;66;03m# 统计每个特征词的词频\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     vector\u001b[38;5;241m.\u001b[39mappend(word_map)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_words' is not defined"
     ]
    }
   ],
   "source": [
    "vector = []\n",
    "for words in all_words:\n",
    "    word_map = list(map(lambda word: words.count(word), top_words))  # 统计每个特征词的词频\n",
    "    vector.append(word_map)\n",
    "vector = np.array(vector)  # 转换为 NumPy 数组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0368416-1b09-49f1-8b7d-3d5de4a5a8ad",
   "metadata": {},
   "source": [
    "### 4.构建分类模型 (MultinomialNB Naive Bayes 模型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19025776-048a-4ac9-bc6a-493d3df69f96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultinomialNB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMultinomialNB\u001b[49m()  \u001b[38;5;66;03m# 初始化多项式朴素贝叶斯模型\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(vector, labels)  \u001b[38;5;66;03m# 使用词频向量和标签进行训练\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MultinomialNB' is not defined"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()  # 初始化多项式朴素贝叶斯模型\n",
    "model.fit(vector, labels)  # 使用词频向量和标签进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed58c46-5dd3-4ef8-9b50-7761b0038bd6",
   "metadata": {},
   "source": [
    "### 5. 对未知邮件进行分类 (predict 函数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9bbd6c-0518-44b9-9ce3-4e7c1ae28c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(filename):\n",
    "    words = get_words(filename)  # 预处理新邮件\n",
    "    current_vector = np.array(tuple(map(lambda word: words.count(word), top_words)))  # 生成词频向量\n",
    "    result = model.predict(current_vector.reshape(1, -1))  # 预测结果\n",
    "    return '垃圾邮件' if result == 1 else '普通邮件'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc87c200-e2d3-4511-be4f-3681484e265a",
   "metadata": {},
   "source": [
    "### 6. 使用 SMOTE 进行数据平衡（后续部分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7aa06c5-8637-4778-89ab-5adaeca7a08c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SMOTE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m smote \u001b[38;5;241m=\u001b[39m \u001b[43mSMOTE\u001b[49m(sampling_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      2\u001b[0m X_res, y_res \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SMOTE' is not defined"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdcc50d-ba30-4241-b09d-f1215b97bc9a",
   "metadata": {},
   "source": [
    "## 高频词/TF-IDF两种特征模式的切换方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ec3d8f-9b3b-4727-82b0-10880d61f11e",
   "metadata": {},
   "source": [
    "### 1.高频词 (Word Frequency) 特征模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1a4e47b-795a-47cc-a1d2-efc86605588c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '。' (U+3002) (4081368457.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    -高频词特征模式是指根据每个词在整个文本中的出现频率来表示文本。该方法简单直观，生成的特征向量通常是每个词在文本中出现的次数。\u001b[0m\n\u001b[1;37m                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '。' (U+3002)\n"
     ]
    }
   ],
   "source": [
    "-高频词特征模式是指根据每个词在整个文本中的出现频率来表示文本。该方法简单直观，生成的特征向量通常是每个词在文本中出现的次数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c280c18-04fb-4c6e-aff8-3f528795decb",
   "metadata": {},
   "source": [
    "### 2. TF-IDF 特征模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "332c1d5c-a327-45bf-aca0-4ccff243c37f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '，' (U+FF0C) (3143140794.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    -TF-IDF 是一种考虑到词频和逆文档频率的加权方法，它不仅反映了一个词在文档中的重要性，还考虑了词在整个语料库中的分布情况。\u001b[0m\n\u001b[1;37m                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '，' (U+FF0C)\n"
     ]
    }
   ],
   "source": [
    "-TF-IDF 是一种考虑到词频和逆文档频率的加权方法，它不仅反映了一个词在文档中的重要性，还考虑了词在整个语料库中的分布情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f9b17-4bd4-46d7-86ea-7678ce56adc7",
   "metadata": {},
   "source": [
    "### 3.如何切换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83fbbbcf-a480-4cec-a556-cd9191f32e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\jixiexuexi\\envs\\nlp_cjl\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:14: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.22.3)\n",
      "  from scipy.sparse import csr_matrix, issparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-frequency features:\n",
      "['email' 'free' 'ham' 'lottery' 'message' 'money' 'sending' 'spam'\n",
      " 'waiting' 'win']\n",
      "\n",
      "TF-IDF features:\n",
      "['email' 'free' 'ham' 'lottery' 'message' 'money' 'sending' 'spam'\n",
      " 'waiting' 'win']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# 假设我们有一个文本数据集\n",
    "documents = [\n",
    "   \"This is a spam message\",\n",
    "   \"This is a ham message\",\n",
    "   \"Free money is waiting for you\",\n",
    "   \"Win a lottery by sending your email\",\n",
    "]\n",
    "# 高频词特征模式：使用 CountVectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "X_count = count_vectorizer.fit_transform(documents)\n",
    "print(\"High-frequency features:\")\n",
    "print(count_vectorizer.get_feature_names_out())  # 输出特征词汇\n",
    "# TF-IDF 特征模式：使用 TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "print(\"\\nTF-IDF features:\")\n",
    "print(tfidf_vectorizer.get_feature_names_out())  # 输出特征词汇"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
